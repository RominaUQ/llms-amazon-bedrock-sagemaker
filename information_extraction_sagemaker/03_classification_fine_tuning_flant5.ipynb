{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - Fine-tuning FLAN-T5 XL\n",
    "\n",
    "The following sections detail the fine-tuning process of the FLAN-T5 XL model using SageMaker JumpStart. This process will improve the model's ability to accurately classify complex and ambiguous queries in our dataset.\n",
    "\n",
    "First, we import the necessary libraries and set up the SageMaker inference instance type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import utils\n",
    "\n",
    "inference_instance_type = \"ml.g5.2xlarge\"\n",
    "\n",
    "model_id, model_version = \"huggingface-text2text-flan-t5-xl\", \"2.0.0\"\n",
    "base_endpoint_name = model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we initialize a base predictor using the `utils` module. This predictor will be utilized to evaluate the model's performance before and after fine-tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictor = utils.get_predictor(\n",
    "    endpoint_name=base_endpoint_name,\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    inference_instance_type=inference_instance_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To validate our deployed model, we conduct a preliminary test using a straightforward prompt: \"What is the capital of France?\" This helps ensure the model's basic functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is the capital of France?\\nResponse:\"\n",
    "response = utils.flant5(base_predictor, user=prompt, max_tokens=2)\n",
    "print(utils.parse_output(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing for fine-tuning requires organizing several files, including the dataset and template files. The dataset is structured to align with the required input format for fine-tuning. For example, each record in our training dataset adheres to the following structure:\n",
    "\n",
    "```json\n",
    "{\"query\": \"customer query\", \"response\": \"main-intent:sub-intent\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_dataset_file = \"data/intent_dataset.jsonl\"\n",
    "intent_dataset_train_file = \"data/intent_dataset_train.jsonl\"\n",
    "intent_dataset_test_file = \"data/intent_dataset_test.jsonl\"\n",
    "ft_template_file = \"data/template.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following creates a template file which will be used by the jumpstart framework to fine-tune the model. The template has two fields, `prompt` and `completion`. These fields are used to pass labeled data to the model for the fine-tuning process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = {\n",
    "    \"prompt\": utils.FT_PROMPT,\n",
    "    \"completion\": \"{response}\",\n",
    "}\n",
    "\n",
    "with open(ft_template_file, \"w\") as f:\n",
    "    json.dump(template, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data is uploaded to an S3 bucket, setting the stage for the actual fine-tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_location = utils.upload_train_and_template_to_s3(\n",
    "    bucket_prefix=\"intent_dataset_flant5\",\n",
    "    train_path=intent_dataset_train_file,\n",
    "    template_path=ft_template_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning the model\n",
    "We configure the JumpStartEstimator, specifying our chosen model and other parameters like instance type and hyperparameters (in this example we use 5 epochs for the training). This estimator will drive the fine-tuning process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We configure the `JumpStartEstimator`, specifying our chosen model and other parameters such as `instance_type` and hyperparameters. This estimator will guide the fine-tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.jumpstart.estimator import JumpStartEstimator\n",
    "\n",
    "estimator = JumpStartEstimator(\n",
    "    model_id=model_id,\n",
    "    disable_output_compression=True,\n",
    "    instance_type=\"ml.g5.24xlarge\",\n",
    "    role=utils.get_role_arn(),\n",
    ")\n",
    "\n",
    "estimator.set_hyperparameters(\n",
    "    instruction_tuned=\"True\", epochs=\"5\", max_input_length=\"1024\"\n",
    ")\n",
    "\n",
    "estimator.fit({\"training\": train_data_location})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you experience a disconnection during training, you can rejoin the ongoing training job by using the code below:\n",
    "\n",
    "```py\n",
    "estimator = JumpStartEstimator.attach(\n",
    "    training_job_name=\"job-name\",\n",
    "    model_id=model_id,\n",
    ")\n",
    "estimator.logs()\n",
    "```\n",
    "\n",
    "You can locate the `training_job_name` in the AWS console or by using [awscli](https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sagemaker/list-training-jobs.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When fine-tuning is completed, we deploy the model to an endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_endpoint_name = \"flan-t5-xl-ft-infoext\"\n",
    "finetuned_model_name = finetuned_endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have already deployed the endpoint, you can run the following code instead of redeploying it:\n",
    "\n",
    "```python\n",
    "finetuned_predictor = utils.get_predictor(\n",
    "    endpoint_name=finetuned_endpoint_name,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploying the finetuned model to an endpoint\n",
    "finetuned_predictor = estimator.deploy(\n",
    "    endpoint_name=finetuned_endpoint_name,\n",
    "    model_name=finetuned_model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's test the fine-tuned model against its base model with ambiguous queries which we saw in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ambiguous_queries = [\n",
    "    {\n",
    "        \"query\": \"I want to change my coverage plan. But I'm not seeing where to do this on the online site. Could you please show me how?\",\n",
    "        \"main_intent\": \"techincal_support\",\n",
    "        \"sub_intent\": \"portal_navigation\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"I'm unhappy with the current benefits of my plan and I'm considering canceling unless there are better alternatives. What can you offer?\",\n",
    "        \"main_intent\": \"customer_retention\",\n",
    "        \"sub_intent\": \"free_product_upgrade\",\n",
    "    },\n",
    "]\n",
    "for query in ambiguous_queries:\n",
    "    question = query[\"query\"]\n",
    "    print(\"query:\", question, \"\\n\")\n",
    "    print(\n",
    "        \"expected intent:  \", f\"{query['main_intent']}:{query['sub_intent']}\"\n",
    "    )\n",
    "\n",
    "    prompt = utils.FT_PROMPT.format(query=question)\n",
    "    response = utils.flant5(base_predictor, user=prompt, max_tokens=13)\n",
    "    print(\"base model:  \", utils.parse_output(response))\n",
    "\n",
    "    response = utils.flant5(finetuned_predictor, user=prompt, max_tokens=13)\n",
    "    print(\"finetuned model:  \", utils.parse_output(response))\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the fine-tuned model can accurately classify ambiguous queries.\n",
    "\n",
    "Finally, we evaluate the fine-tuned model's performance using the test dataset to benchmark its overall accuracy, and for each specific intent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = utils.load_dataset(intent_dataset_test_file)\n",
    "\n",
    "res = utils.evaluate_model(\n",
    "    predictor=finetuned_predictor,\n",
    "    llm=utils.flant5,\n",
    "    dataset=test_dataset,\n",
    "    prompt_template=utils.FT_PROMPT,\n",
    "    response_formatter=utils.flant5_output_intent_formatter,\n",
    ")\n",
    "\n",
    "utils.print_eval_result(res, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To evaluate the base model, we can pass `base_predictor` to the `evaluate` function.\n",
    "\n",
    "In this notebook, we have enhanced our model's performance through the fine-tuning process. By optimizing a smaller model (i.e. FlanT5-XL) for complex classification tasks, we have attained better accuracy compared to the in-context learning approach utilized with much larger models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
